# turkish-ngram-model
A Turkish language model using n-grams (1-gram, 2-gram, 3-gram) built on the Turkish Wikipedia Dump dataset. Includes character and syllable tokenization, training-test data preparation, and random sentence generation for NLP tasks and language modeling.

# Important Notes
I have use wiki-Turkish-dump dataset from Kaggle to build this porject. If you want to use your own dataset, you need to change the "FILE_NAME" parameter in DataPrep.py
![Screenshot 2024-11-27 at 01 10 00](https://github.com/user-attachments/assets/2945263d-fb83-4918-9785-e856068f4178)
